{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f745538-23a3-4abb-aefb-e6d1ce4aef10",
   "metadata": {},
   "source": [
    "# Spam Email Classification using a Naive Bayes Classifier and NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed4c57-f4d4-4d0c-95f1-ba6c9d3a8507",
   "metadata": {},
   "source": [
    "The Spam Email Classification system is the implementation of a machine learning based model, specifically using the Naive Bayes classifier, that allows us to categorize input mail as either spam or not spam. The training has been performed on a dataset provided, and implemented using NLTK with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759c7cd-5e0e-4b3f-afa8-a36c5c472365",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afa37378-7ad5-4b12-89f8-3351e9aafe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe1f5c-e9da-43a6-bc4e-1cd1e3261733",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bb708-be1f-4c07-84e0-4c3dfbe71efb",
   "metadata": {},
   "source": [
    "Dataset description.\n",
    "The dataset used to train the model is the Email Spam Classification Dataset CSV from Kaggle.\n",
    "The dataset contains 5172 rows, with 3002 columns\n",
    "The first column indicates Email name, and the last column has the labels for prediction : 1 for spam, 0 for not spam. The remaining 3000 columns are the 3000 most common words in all the emails, after excluding the non-alphabetical characters/words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ef1a52c-6504-45bb-9910-252ed1d3ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  \\\n",
      "0        Email 1    0   0    1    0    0   0    2    0    0  ...         0   \n",
      "1        Email 2    8  13   24    6    6   2  102    1   27  ...         0   \n",
      "2        Email 3    0   0    1    0    0   0    8    0    0  ...         0   \n",
      "3        Email 4    0   5   22    0    5   1   51    2   10  ...         0   \n",
      "4        Email 5    7   6   17    1    5   2   57    0    9  ...         0   \n",
      "...          ...  ...  ..  ...  ...  ...  ..  ...  ...  ...  ...       ...   \n",
      "5167  Email 5168    2   2    2    3    0   0   32    0    0  ...         0   \n",
      "5168  Email 5169   35  27   11    2    6   5  151    4    3  ...         0   \n",
      "5169  Email 5170    0   0    1    1    0   0   11    0    0  ...         0   \n",
      "5170  Email 5171    2   7    1    0    2   1   28    2    0  ...         0   \n",
      "5171  Email 5172   22  24    5    1    6   5  148    8    2  ...         0   \n",
      "\n",
      "      jay  valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
      "0       0       0    0               0         0         0   0    0   \n",
      "1       0       0    0               0         0         0   1    0   \n",
      "2       0       0    0               0         0         0   0    0   \n",
      "3       0       0    0               0         0         0   0    0   \n",
      "4       0       0    0               0         0         0   1    0   \n",
      "...   ...     ...  ...             ...       ...       ...  ..  ...   \n",
      "5167    0       0    0               0         0         0   0    0   \n",
      "5168    0       0    0               0         0         0   1    0   \n",
      "5169    0       0    0               0         0         0   0    0   \n",
      "5170    0       0    0               0         0         0   1    0   \n",
      "5171    0       0    0               0         0         0   0    0   \n",
      "\n",
      "      Prediction  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "...          ...  \n",
      "5167           0  \n",
      "5168           0  \n",
      "5169           1  \n",
      "5170           1  \n",
      "5171           0  \n",
      "\n",
      "[5172 rows x 3002 columns]\n"
     ]
    }
   ],
   "source": [
    "#import dataset\n",
    "dataset = pd.read_csv(r'C:\\Users\\wigox\\Downloads\\archive (3)\\emails.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae4aed-2df8-490c-a34e-b60fa35b5da8",
   "metadata": {},
   "source": [
    "## On the Preprocessing of the Dataset\n",
    "\n",
    "The dataset contains the most common words in all the emails, therefore, it has been preprocessed and does not require further preprocessing such as;\n",
    "- the removal of stop words\n",
    "- removing of alphanumeric characters\n",
    "- tokenization of the dataset\n",
    "- removing of punctuation\n",
    "\n",
    "However, preprocessing using the NLTK Library would still be necessary for the content of input email, as the input email would most likely contain stop words, punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ad2432c-019d-43ec-a718-1b308758bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb2e3f-9f60-4d3b-97b6-6ac4bfa8ea56",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4283fbb-6e6e-4b0e-8625-0cd798bda8bc",
   "metadata": {},
   "source": [
    "- The model is trained using Naive bayes classifier, it works by categorizing an email being spam or not by calculating the likelihood of its words appearing in spam or non-spam emails, and assumes all words contribute independently to the classification.\n",
    "\n",
    "- Since the dataset provided to us is of a moderate size, it is assumed that Naive Bayes will perform well because it assumes feature independence, which often works well for text data (like words in an email)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba447bd9-35ca-4926-8284-64e22f6e12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features and labels\n",
    "X = dataset.iloc[:, 1:-1]  \n",
    "# removing the email name and labels columns\n",
    "y = dataset.iloc[:, -1]   \n",
    "# specifying the target (Labels) column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3debc9-ec15-4bf1-8e93-fcb88e4a8b11",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7eeeb1f9-5e49-4d4d-a2a3-c9e94e043da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b8b24-dbfa-4669-8e4a-2d1a5be64255",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc5231a8-99a7-4dac-b757-742e6f2557f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ed73b4-fc2e-42b5-97ff-7610a3823816",
   "metadata": {},
   "source": [
    "### Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "037d72ee-5910-48fb-af2b-b452f5b955ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea10ed-1a68-44ee-b56d-0966809f16d8",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e33058c4-4658-4356-bef0-ada9b4ea4e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9545893719806763\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       739\n",
      "           1       0.89      0.96      0.92       296\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.94      0.96      0.95      1035\n",
      "weighted avg       0.96      0.95      0.96      1035\n",
      "\n",
      "F1 Score:  0.9235772357723576\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c143ca-f767-4bbe-a972-059507754e4b",
   "metadata": {},
   "source": [
    "## Using NLTK to preprocess the input email.\n",
    "\n",
    "In this step, stop words are removed, and stemming is performed with the use of stemmer to preprocess the input email.\n",
    "After this, the email is broken down into tokens which are then passed into the model for prediction.\n",
    "\n",
    "After passing the tokens through the trained model, it will be able to predict whether the tokens passed into it are spam or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74331d11-661e-4481-af55-c9ae439568ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wigox\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wigox\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stop words and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess(text): \n",
    "  if isinstance(text, str): \n",
    "    tokens = word_tokenize(text.lower()) \n",
    "    tokens = [word for word in tokens if word.isalpha()]  \n",
    "    tokens = [word for word in tokens if word not in stop_words]  \n",
    "    tokens = [stemmer.stem(word) for word in tokens] \n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset['processed_message'] = dataset['message'].apply(preprocess)\n",
    "email_content = dataset['processed_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3392ce-c00f-416a-9ae8-93a100ca1e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
